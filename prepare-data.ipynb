{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data from URL into memory\n",
    "2. Parse data using pre-defined rules (mostly removing outliers)\n",
    "3. Output data as CSV. For the training set (set-a), also output the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://physionet.org/challenge/2012/set-a.zip\n",
    "!wget https://physionet.org/challenge/2012/set-b.zip\n",
    "\n",
    "!wget https://physionet.org/challenge/2012/Outcomes-a.txt\n",
    "!wget https://physionet.org/challenge/2012/Outcomes-b.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -u set-a.zip\n",
    "!unzip -u set-b.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# pick a set\n",
    "dataset = 'set-b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate static values with duplicate entries\n",
    "df_static.loc[df_static[['recordid', 'parameter']].duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_static.loc[df_static['recordid'] == 149509, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load all files into list of lists\n",
    "txt_all = list()\n",
    "for f in os.listdir(dataset):\n",
    "    with open(os.path.join(dataset, f), 'r') as fp:\n",
    "        txt = fp.readlines()\n",
    "        \n",
    "    # get recordid to add as a column\n",
    "    recordid = txt[1].rstrip('\\n').split(',')[-1]\n",
    "    txt = [t.rstrip('\\n').split(',') + [int(recordid)] for t in txt]\n",
    "    txt_all.extend(txt[1:])\n",
    "    \n",
    "    \n",
    "# convert to pandas dataframe\n",
    "df = pd.DataFrame(txt_all, columns=['time', 'parameter', 'value', 'recordid'])\n",
    "\n",
    "# extract static variables into a separate dataframe\n",
    "df_static = df.loc[df['time'] == '00:00', :].copy()\n",
    "\n",
    "# retain only one of the 6 static vars:\n",
    "static_vars = ['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight']\n",
    "df_static = df_static.loc[df['parameter'].isin(static_vars)]\n",
    "\n",
    "# remove these from original df\n",
    "idxDrop = df_static.index\n",
    "df = df.loc[~df.index.isin(idxDrop), :]\n",
    "\n",
    "# to ensure there are no duplicates, group by recordid/parameter and take the last value\n",
    "# last will be chosen as last row in the loaded file\n",
    "# there was 1 row in set-b which had 2 weights (70.4, 70.8) and thus required this step\n",
    "df_static = df_static.groupby(['recordid', 'parameter'])[['value']].last()\n",
    "df_static.reset_index(inplace=True)\n",
    "\n",
    "# pivot on parameter so there is one column per parameter\n",
    "df_static = df_static.pivot(index='recordid', columns='parameter', values='value')\n",
    "\n",
    "# some conversions on columns for convenience\n",
    "df['value'] = pd.to_numeric(df['value'], errors='raise')\n",
    "df['time'] = df['time'].map(lambda x: int(x.split(':')[0])*60 + int(x.split(':')[1]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'Albumin': 'Serum Albumin (g/dL)',\n",
    "    'ALP': 'Alkaline phosphatase (IU/L)',\n",
    "    'ALT': 'Alanine transaminase (IU/L)',\n",
    "    'AST': 'Aspartate transaminase (IU/L)',\n",
    "    'Bilirubin': 'Bilirubin (mg/dL)',\n",
    "    'BUN': 'Blood urea nitrogen (mg/dL)',\n",
    "    'Cholesterol': 'Cholesterol (mg/dL)',\n",
    "    'Creatinine': 'Serum creatinine (mg/dL)',\n",
    "    'DiasABP': 'Invasive diastolic arterial blood pressure (mmHg)',\n",
    "    'FiO2': 'Fractional inspired O2 (0-1)',\n",
    "    'GCS': 'Glasgow Coma Score (3-15)',\n",
    "    'Glucose': 'Serum glucose (mg/dL)',\n",
    "    'HCO3': 'Serum bicarbonate (mmol/L)',\n",
    "    'HCT': 'Hematocrit (%)',\n",
    "    'HR': 'Heart rate (bpm)',\n",
    "    'K': 'Serum potassium (mEq/L)',\n",
    "    'Lactate': 'Lactate (mmol/L)',\n",
    "    'Mg': 'Serum magnesium (mmol/L)',\n",
    "    'MAP': 'Invasive mean arterial blood pressure (mmHg)',\n",
    "    'MechVent': 'Mechanical ventilation respiration (0:false or 1:true)',\n",
    "    'Na': 'Serum sodium (mEq/L)',\n",
    "    'NIDiasABP': 'Non-invasive diastolic arterial blood pressure (mmHg)',\n",
    "    'NIMAP': 'Non-invasive mean arterial blood pressure (mmHg)',\n",
    "    'NISysABP': 'Non-invasive systolic arterial blood pressure (mmHg)',\n",
    "    'PaCO2': 'partial pressure of arterial CO2 (mmHg)',\n",
    "    'PaO2': 'Partial pressure of arterial O2 (mmHg)',\n",
    "    'pH': 'Arterial pH (0-14)',\n",
    "    'Platelets': 'Platelets (cells/nL)',\n",
    "    'RespRate': 'Respiration rate (bpm)',\n",
    "    'SaO2': 'O2 saturation in hemoglobin (%)',\n",
    "    'SysABP': 'Invasive systolic arterial blood pressure (mmHg)',\n",
    "    'Temp': 'Temperature (°C)',\n",
    "    'TroponinI': 'Troponin-I (μg/L)',\n",
    "    'TroponinT': 'Troponin-T (μg/L)',\n",
    "    'Urine': 'Urine output (mL)',\n",
    "    'WBC': 'White blood cell count (cells/nL)',\n",
    "    'Weight': 'Weight (kg)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert static into numeric\n",
    "for c in df_static.columns:\n",
    "    df_static[c] = pd.to_numeric(df_static[c])\n",
    "    \n",
    "# preprocess\n",
    "for c in df_static.columns:\n",
    "    x = df_static[c]\n",
    "    if c == 'Age':\n",
    "        # replace anon ages with 91.4\n",
    "        idx = x > 130\n",
    "        df_static.loc[idx, c] = 91.4\n",
    "    elif c == 'Gender':\n",
    "        idx = x < 0\n",
    "        df_static.loc[idx, c] = np.nan\n",
    "    elif c == 'Height':\n",
    "        idx = x < 0\n",
    "        df_static.loc[idx, c] = np.nan\n",
    "        \n",
    "        # fix incorrectly recorded heights\n",
    "        \n",
    "        # 1.8 -> 180\n",
    "        idx = x < 10\n",
    "        df_static.loc[idx, c] = df_static.loc[idx, c] * 100\n",
    "        \n",
    "        # 18 -> 180\n",
    "        idx = x < 25\n",
    "        df_static.loc[idx, c] = df_static.loc[idx, c] * 10\n",
    "        \n",
    "        # 81.8 -> 180 (inch -> cm)\n",
    "        idx = x < 100\n",
    "        df_static.loc[idx, c] = df_static.loc[idx, c] * 2.2\n",
    "        \n",
    "        # 1800 -> 180\n",
    "        idx = x > 1000\n",
    "        df_static.loc[idx, c] = df_static.loc[idx, c] * 0.1\n",
    "        \n",
    "        # 400 -> 157\n",
    "        idx = x > 250\n",
    "        df_static.loc[idx, c] = df_static.loc[idx, c] * 0.3937\n",
    "        \n",
    "    elif c == 'Weight':\n",
    "        idx = x < 35\n",
    "        df_static.loc[idx, c] = np.nan\n",
    "        \n",
    "        idx = x > 299\n",
    "        df_static.loc[idx, c] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_value(df, c, value=0):\n",
    "    idx = df['parameter'] == c\n",
    "    idx = idx & (df['value'] == value)\n",
    "    \n",
    "    df.loc[idx, 'value'] = np.nan\n",
    "    return df\n",
    "\n",
    "def replace_value(df, c, value=np.nan, below=None, above=None):\n",
    "    idx = df['parameter'] == c\n",
    "    \n",
    "    if below is not None:\n",
    "        idx = idx & (df['value'] < below)\n",
    "        \n",
    "    if above is not None:\n",
    "        idx = idx & (df['value'] > above)\n",
    "    \n",
    "    \n",
    "    if 'function' in str(type(value)):\n",
    "        # value replacement is a function of the input\n",
    "        df.loc[idx, 'value'] = df.loc[idx, 'value'].apply(value)\n",
    "    else:\n",
    "        df.loc[idx, 'value'] = value\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply dynamic data rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_value(df, 'DiasABP', -1)\n",
    "df = replace_value(df, 'DiasABP', value=np.nan, below=1)\n",
    "df = replace_value(df, 'DiasABP', value=np.nan, above=200)\n",
    "df = replace_value(df, 'SysABP', value=np.nan, below=1)\n",
    "df = replace_value(df, 'MAP', value=np.nan, below=1)\n",
    "\n",
    "df = replace_value(df, 'NIDiasABP', value=np.nan, below=1)\n",
    "df = replace_value(df, 'NISysABP', value=np.nan, below=1)\n",
    "df = replace_value(df, 'NIMAP', value=np.nan, below=1)\n",
    "\n",
    "df = replace_value(df, 'HR', value=np.nan, below=1)\n",
    "df = replace_value(df, 'HR', value=np.nan, above=299)\n",
    "\n",
    "df = replace_value(df, 'PaCO2', value=np.nan, below=1)\n",
    "df = replace_value(df, 'PaCO2', value=lambda x: x*10, below=10)\n",
    "\n",
    "df = replace_value(df, 'PaO2', value=np.nan, below=1)\n",
    "df = replace_value(df, 'PaO2', value=lambda x: x*10, below=20)\n",
    "\n",
    "# the order of these steps matters\n",
    "df = replace_value(df, 'pH', value=lambda x: x*10, below=0.8, above=0.65)\n",
    "df = replace_value(df, 'pH', value=lambda x: x*0.1, below=80, above=65)\n",
    "df = replace_value(df, 'pH', value=lambda x: x*0.01, below=800, above=650)\n",
    "df = replace_value(df, 'pH', value=np.nan, below=6.5)\n",
    "df = replace_value(df, 'pH', value=np.nan, above=8.0)\n",
    "\n",
    "# convert to farenheit\n",
    "df = replace_value(df, 'Temp', value=lambda x: x*9/5+32, below=10, above=1)\n",
    "df = replace_value(df, 'Temp', value=lambda x: (x-32)*5/9, below=113, above=95)\n",
    "df = replace_value(df, 'Temp', value=np.nan, below=90)\n",
    "df = replace_value(df, 'Temp', value=np.nan, above=119)\n",
    "\n",
    "df = replace_value(df, 'RespRate', value=np.nan, below=1)\n",
    "df = replace_value(df, 'WBC', value=np.nan, below=1)\n",
    "\n",
    "df = replace_value(df, 'Weight', value=np.nan, below=35)\n",
    "df = replace_value(df, 'Weight', value=np.nan, above=299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a design matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a dataframe with df_static\n",
    "X = df_static.copy()\n",
    "\n",
    "X.drop('RecordID', axis=1, inplace=True)\n",
    "\n",
    "# MICU is ICUType==3, and is used as the reference category\n",
    "X['CCU'] = (X['ICUType'] == 1).astype(int)\n",
    "X['CSRU'] = (X['ICUType'] == 2).astype(int)\n",
    "X['SICU'] = (X['ICUType'] == 4).astype(int)\n",
    "X.drop('ICUType', axis=1, inplace=True)\n",
    "\n",
    "# For the following features we extract: first, last, lowest, highest, median\n",
    "feats = ['DiasABP', 'GCS', 'Glucose', 'HR', 'MAP',\n",
    "'NIDiasABP', 'NIMAP', 'NISysABP', \n",
    "'RespRate', 'SaO2', 'Temp', ]\n",
    "\n",
    "idx = df['parameter'].isin(feats)\n",
    "df_tmp = df.loc[idx, :].copy()\n",
    "df_tmp = df_tmp.groupby(['recordid', 'parameter'])['value']\n",
    "\n",
    "for agg in ['first', 'last', 'lowest', 'highest', 'median']:\n",
    "    if agg == 'first':\n",
    "        X_add = df_tmp.first()\n",
    "    elif agg == 'last':\n",
    "        X_add = df_tmp.last()\n",
    "    elif agg == 'lowest':\n",
    "        X_add = df_tmp.min()\n",
    "    elif agg == 'highest':\n",
    "        X_add = df_tmp.max()\n",
    "    elif agg == 'median':\n",
    "        X_add = df_tmp.median()\n",
    "    else:\n",
    "        print('Unrecognized aggregation {}. Skipping.'.format(agg))\n",
    "        \n",
    "    X_add = X_add.reset_index()\n",
    "    X_add = X_add.pivot(index='recordid', columns='parameter', values='value')\n",
    "    X_add.columns = [x + '_' + agg for x in X_add.columns]\n",
    "\n",
    "    X = X.merge(X_add, how='left', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# For the following features we extract: first, last\n",
    "feats = ['Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol',\n",
    "'Creatinine', 'FiO2', 'HCO3', 'HCT', 'K', 'Lactate', 'Mg', 'Na',\n",
    "'PaCO2', 'PaO2', 'pH', 'Platelets', 'SysABP', 'TroponinI', 'TroponinT',\n",
    "'WBC', 'Weight']\n",
    "\n",
    "\n",
    "idx = df['parameter'].isin(feats)\n",
    "df_tmp = df.loc[idx, :].copy()\n",
    "df_tmp = df_tmp.groupby(['recordid', 'parameter'])['value']\n",
    "\n",
    "for agg in ['first', 'last']:\n",
    "    if agg == 'first':\n",
    "        X_add = df_tmp.first()\n",
    "    elif agg == 'last':\n",
    "        X_add = df_tmp.last()\n",
    "    elif agg == 'lowest':\n",
    "        X_add = df_tmp.min()\n",
    "    elif agg == 'highest':\n",
    "        X_add = df_tmp.max()\n",
    "    elif agg == 'median':\n",
    "        X_add = df_tmp.median()\n",
    "    else:\n",
    "        print('Unrecognized aggregation {}. Skipping.'.format(agg))\n",
    "        \n",
    "    X_add = X_add.reset_index()\n",
    "    X_add = X_add.pivot(index='recordid', columns='parameter', values='value')\n",
    "    X_add.columns = [x + '_' + agg for x in X_add.columns]\n",
    "\n",
    "    X = X.merge(X_add, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# For the following features we extract custom data\n",
    "idx = df['parameter'] == 'MechVent'\n",
    "df_tmp = df.loc[idx, :].copy().groupby('recordid')\n",
    "\n",
    "X0 = df_tmp[['time']].min()\n",
    "X0.columns = ['MechVentStartTime']\n",
    "\n",
    "X1 = df_tmp[['time']].max()\n",
    "X1.columns = ['MechVentEndTime']\n",
    "\n",
    "X_add = X0.merge(X1, how='inner',\n",
    "                 left_index=True, right_index=True)\n",
    "X_add['MechVentDuration'] = X_add['MechVentEndTime'] - X_add['MechVentStartTime']\n",
    "\n",
    "X_add['MechVentLast8Hour'] = (X_add['MechVentEndTime'] >= 2400).astype(int)\n",
    "X_add.drop('MechVentEndTime', axis=1, inplace=True)\n",
    "\n",
    "X = X.merge(X_add, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Urine output\n",
    "idx = df['parameter'] == 'MechVent'\n",
    "df_tmp = df.loc[idx, :].copy().groupby('recordid')\n",
    "\n",
    "X_add = df_tmp[['value']].sum()\n",
    "X_add.columns = ['UrineOutputSum']\n",
    "\n",
    "X = X.merge(X_add, how='left', left_index=True, right_index=True)\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in outcomes\n",
    "if dataset == 'set-a':\n",
    "    y = pd.read_csv('Outcomes-a.txt')\n",
    "elif dataset == 'set-b':\n",
    "    y = pd.read_csv('Outcomes-b.txt')\n",
    "    \n",
    "y.set_index('RecordID', inplace=True)\n",
    "y.index.name = 'recordid'\n",
    "X = y.merge(X, how='inner', left_index=True, right_index=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to file\n",
    "X.to_csv('PhysionetChallenge2012-{}.csv.gz'.format(dataset),\n",
    "         sep=',', index=True, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-tutorial",
   "language": "python",
   "name": "tree-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
